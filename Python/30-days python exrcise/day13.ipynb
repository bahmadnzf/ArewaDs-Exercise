{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "Regular Expressions Exercises:\n",
    "Exercises: Level 1:\n",
    "\n",
    "1. What is the most frequent word in the following paragraph?    \n",
    "\n",
    "paragraph = 'I love teaching. If you do not love teaching what else can you love. I love Python if you do not love something which can give you all the capabilities to develop an application what else can you love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent word is \"love\" which appears 6 times.\n"
     ]
    }
   ],
   "source": [
    "paragraph = ' I love teaching. If you do not love teaching what else can you love. I love Python if you do not love something which can give you all the capabilities to develop an application what else can you love.'    \n",
    "from collections import Counter  \n",
    "import re  \n",
    "\n",
    "# Use Regular Expressions to remove punctuation and make everything lowercase  \n",
    "words = re.findall(r'\\b\\w+\\b', paragraph.lower())  \n",
    "\n",
    "# Count the frequency of each word  \n",
    "word_count = Counter(words)  \n",
    "\n",
    "# Find the most common word  \n",
    "most_common_word, most_common_count = word_count.most_common(1)[0]  \n",
    "\n",
    "# Output the result \n",
    "print(f'The most frequent word is \"{most_common_word}\" which appears {most_common_count} times.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the negative direction, 0 at origin, 4 and 8 in the positive direction. Extract these numbers from this whole text and find the distance between the two furthest particles.\n",
    "points = ['-12', '-4', '-3', '-1', '0', '4', '8']\n",
    "sorted_points =  [-12, -4, -3, -1, -1, 0, 2, 4, 8]\n",
    "distance = 8 -(-12) # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted points: [-12, -4, -3, -1, 0, 4, 8]\n",
      "The distance between the two furthest particles is: 20\n"
     ]
    }
   ],
   "source": [
    "points = ['-12', '-4', '-3', '-1', '0', '4', '8']\n",
    "sorted_points =  [-12, -4, -3, -1, -1, 0, 2, 4, 8]\n",
    "distance = 8 -(-12) # 20\n",
    "import re  \n",
    "\n",
    "# Given text containing the positions of the particles  \n",
    "text = ('The position of some particles on the horizontal x-axis are -12, -4, -3 and -1 in the '  \n",
    "        'negative direction, 0 at origin, 4 and 8 in the positive direction.')  \n",
    "\n",
    "# Use regular expressions to find all integers (positive and negative) in the text  \n",
    "points = list(map(int, re.findall(r'-?\\d+', text)))  \n",
    "\n",
    "# Find the furthest particles  \n",
    "max_position = max(points)  \n",
    "min_position = min(points)  \n",
    "\n",
    "# Calculate the distance between the two furthest particles  \n",
    "distance = max_position - min_position  \n",
    "\n",
    "# Output the results  \n",
    "print(f\"Extracted points: {points}\")  \n",
    "print(f\"The distance between the two furthest particles is: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises: Level 2\n",
    "1.Write a pattern which identifies if a string is a valid python variable\n",
    "is_valid_variable('first_name') # True\n",
    "is_valid_variable('first-name') # False\n",
    "is_valid_variable('1first_name') # False\n",
    "is_valid_variable('firstname') # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "\n",
    "def is_valid_variable(variable_name):  \n",
    "    # Regular expression pattern for a valid Python variable name  \n",
    "    # ^[a-zA-Z_][a-zA-Z0-9_]*$ - Matches starting with a letter or underscore, followed by letters, digits, or underscores.  \n",
    "    pattern = r'^[a-zA-Z_][a-zA-Z0-9_]*$'  \n",
    "    \n",
    "    return bool(re.match(pattern, variable_name))  \n",
    "\n",
    "# Test cases  \n",
    "print(is_valid_variable('first_name'))  # True  \n",
    "print(is_valid_variable('first-name'))   # False  \n",
    "print(is_valid_variable('1first_name'))  # False  \n",
    "print(is_valid_variable('firstname'))     # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises: Level 3\n",
    "Clean the following text. After cleaning, count three most frequent words in the string.\n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''\n",
    "\n",
    "print(clean_text(sentence));\n",
    "I am a teacher and I love teaching There is nothing as more rewarding as educating and empowering people I found teaching more interesting than any other jobs Does this motivate you to be a teacher\n",
    "print(most_frequent_words(cleaned_text)) # [(3, 'I'), (2, 'teaching'), (2, 'teacher')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i  am   a  tea cher    and  i lo  ve  tea ching    there  is nothing   as  mo re rewarding as educa ting  and   emp o wering peo ple   i found tea ching m o re interesting tha n any other  jo bs   do es thi s mo tivate yo u to be a tea cher\n",
      "[('tea', 4), ('i', 3), ('a', 2)]\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "from collections import Counter  \n",
    "\n",
    "def clean_text(sentence):  \n",
    "    # Remove unwanted characters using regex and normalize to lowercase  \n",
    "    cleaned_sentence = re.sub(r'[^a-zA-Z\\s]', ' ', sentence)  \n",
    "    cleaned_sentence = cleaned_sentence.lower()  \n",
    "    return cleaned_sentence.strip()  \n",
    "\n",
    "def most_frequent_words(cleaned_text):  \n",
    "    # Split the cleaned text into words  \n",
    "    words = cleaned_text.split()  \n",
    "    \n",
    "    # Count the frequency of each word  \n",
    "    word_count = Counter(words)  \n",
    "    \n",
    "    # Get the three most common words  \n",
    "    most_common = word_count.most_common(3)  \n",
    "    \n",
    "    return most_common  \n",
    "\n",
    "# Given sentence to clean  \n",
    "sentence = '''%I $am@% a %tea@cher%, &and& I lo%#ve %tea@ching%;. There $is nothing; &as& mo@re rewarding as educa@ting &and& @emp%o@wering peo@ple. ;I found tea@ching m%o@re interesting tha@n any other %jo@bs. %Do@es thi%s mo@tivate yo@u to be a tea@cher!?'''  \n",
    "\n",
    "# Clean the text  \n",
    "cleaned_text = clean_text(sentence)  \n",
    "print(cleaned_text)  \n",
    "\n",
    "# Find and print the three most frequent words  \n",
    "print(most_frequent_words(cleaned_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
